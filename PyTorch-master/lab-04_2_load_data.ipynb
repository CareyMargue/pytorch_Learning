{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4-2: Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Seungjae Lee (이승재)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    We use elemental PyTorch to implement linear regression here. However, in most actual applications, abstractions such as <code>nn.Module</code> or <code>nn.Linear</code> are used.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing 1D Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [0, 1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "print(nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "index 2에서 4 전까지 가져와라. (앞 포함, 뒤 비포함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3]\n"
     ]
    }
   ],
   "source": [
    "print(nums[2:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "index 2부터 다 가져와라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "print(nums[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "index 2 전까지 가져와라. (역시 뒤는 비포함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(nums[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전부 가져와라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "print(nums[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막 index 전까지 가져와라. (뒤는 비포함!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "print(nums[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "assign 도 가능!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums[2:4] = [8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 8, 9, 4]\n"
     ]
    }
   ],
   "source": [
    "print(nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing 2D Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]]\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  6, 10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 10, 11, 12])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 10, 11, 12])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 10, 11, 12])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[-1, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [5, 6, 7, 8]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0:2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data from `.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 73.  80.  75. 152.]\n",
      " [ 93.  88.  93. 185.]\n",
      " [ 89.  91.  90. 180.]\n",
      " [ 96.  98. 100. 196.]\n",
      " [ 73.  66.  70. 142.]\n",
      " [ 53.  46.  55. 101.]\n",
      " [ 69.  74.  77. 149.]\n",
      " [ 47.  56.  60. 115.]\n",
      " [ 87.  79.  90. 175.]\n",
      " [ 79.  70.  88. 164.]\n",
      " [ 69.  70.  73. 141.]\n",
      " [ 70.  65.  74. 141.]\n",
      " [ 93.  95.  91. 184.]\n",
      " [ 79.  80.  73. 152.]\n",
      " [ 70.  73.  78. 148.]\n",
      " [ 93.  89.  96. 192.]\n",
      " [ 78.  75.  68. 147.]\n",
      " [ 81.  90.  93. 183.]\n",
      " [ 88.  92.  86. 177.]\n",
      " [ 78.  83.  77. 159.]\n",
      " [ 82.  86.  90. 177.]\n",
      " [ 86.  82.  89. 175.]\n",
      " [ 78.  83.  85. 175.]\n",
      " [ 76.  83.  71. 149.]\n",
      " [ 96.  93.  95. 192.]]\n"
     ]
    }
   ],
   "source": [
    "xy = np.loadtxt('data-01-test-score.csv', delimiter=',', dtype=np.float32)\n",
    "print(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 3)\n",
      "25\n",
      "[[ 73.  80.  75.]\n",
      " [ 93.  88.  93.]\n",
      " [ 89.  91.  90.]\n",
      " [ 96.  98. 100.]\n",
      " [ 73.  66.  70.]]\n"
     ]
    }
   ],
   "source": [
    "print(x_data.shape) # x_data shape\n",
    "print(len(x_data))  # x_data 길이\n",
    "print(x_data[:5])   # 첫 다섯 개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 1)\n",
      "25\n",
      "[[152.]\n",
      " [185.]\n",
      " [180.]\n",
      " [196.]\n",
      " [142.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_data.shape) # y_data shape\n",
    "print(len(y_data))  # y_data 길이\n",
    "print(y_data[:5])   # 첫 다섯 개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e07fd5abb0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For reproducibility\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low-level Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/200 Cost: 26811.960938\n",
      "Epoch    1/200 Cost: 9920.530273\n",
      "Epoch    2/200 Cost: 3675.298828\n",
      "Epoch    3/200 Cost: 1366.260986\n",
      "Epoch    4/200 Cost: 512.542297\n",
      "Epoch    5/200 Cost: 196.896500\n",
      "Epoch    6/200 Cost: 80.190903\n",
      "Epoch    7/200 Cost: 37.038647\n",
      "Epoch    8/200 Cost: 21.081354\n",
      "Epoch    9/200 Cost: 15.178741\n",
      "Epoch   10/200 Cost: 12.993667\n",
      "Epoch   11/200 Cost: 12.183028\n",
      "Epoch   12/200 Cost: 11.880545\n",
      "Epoch   13/200 Cost: 11.765953\n",
      "Epoch   14/200 Cost: 11.720860\n",
      "Epoch   15/200 Cost: 11.701425\n",
      "Epoch   16/200 Cost: 11.691506\n",
      "Epoch   17/200 Cost: 11.685120\n",
      "Epoch   18/200 Cost: 11.680006\n",
      "Epoch   19/200 Cost: 11.675381\n",
      "Epoch   20/200 Cost: 11.670943\n",
      "Epoch   21/200 Cost: 11.666553\n",
      "Epoch   22/200 Cost: 11.662214\n",
      "Epoch   23/200 Cost: 11.657912\n",
      "Epoch   24/200 Cost: 11.653568\n",
      "Epoch   25/200 Cost: 11.649248\n",
      "Epoch   26/200 Cost: 11.644933\n",
      "Epoch   27/200 Cost: 11.640630\n",
      "Epoch   28/200 Cost: 11.636309\n",
      "Epoch   29/200 Cost: 11.632007\n",
      "Epoch   30/200 Cost: 11.627703\n",
      "Epoch   31/200 Cost: 11.623416\n",
      "Epoch   32/200 Cost: 11.619119\n",
      "Epoch   33/200 Cost: 11.614834\n",
      "Epoch   34/200 Cost: 11.610538\n",
      "Epoch   35/200 Cost: 11.606255\n",
      "Epoch   36/200 Cost: 11.601980\n",
      "Epoch   37/200 Cost: 11.597700\n",
      "Epoch   38/200 Cost: 11.593445\n",
      "Epoch   39/200 Cost: 11.589173\n",
      "Epoch   40/200 Cost: 11.584903\n",
      "Epoch   41/200 Cost: 11.580639\n",
      "Epoch   42/200 Cost: 11.576386\n",
      "Epoch   43/200 Cost: 11.572125\n",
      "Epoch   44/200 Cost: 11.567865\n",
      "Epoch   45/200 Cost: 11.563633\n",
      "Epoch   46/200 Cost: 11.559365\n",
      "Epoch   47/200 Cost: 11.555134\n",
      "Epoch   48/200 Cost: 11.550891\n",
      "Epoch   49/200 Cost: 11.546656\n",
      "Epoch   50/200 Cost: 11.542419\n",
      "Epoch   51/200 Cost: 11.538205\n",
      "Epoch   52/200 Cost: 11.533975\n",
      "Epoch   53/200 Cost: 11.529764\n",
      "Epoch   54/200 Cost: 11.525549\n",
      "Epoch   55/200 Cost: 11.521326\n",
      "Epoch   56/200 Cost: 11.517120\n",
      "Epoch   57/200 Cost: 11.512906\n",
      "Epoch   58/200 Cost: 11.508705\n",
      "Epoch   59/200 Cost: 11.504499\n",
      "Epoch   60/200 Cost: 11.500296\n",
      "Epoch   61/200 Cost: 11.496106\n",
      "Epoch   62/200 Cost: 11.491939\n",
      "Epoch   63/200 Cost: 11.487738\n",
      "Epoch   64/200 Cost: 11.483567\n",
      "Epoch   65/200 Cost: 11.479369\n",
      "Epoch   66/200 Cost: 11.475198\n",
      "Epoch   67/200 Cost: 11.471023\n",
      "Epoch   68/200 Cost: 11.466857\n",
      "Epoch   69/200 Cost: 11.462695\n",
      "Epoch   70/200 Cost: 11.458522\n",
      "Epoch   71/200 Cost: 11.454372\n",
      "Epoch   72/200 Cost: 11.450214\n",
      "Epoch   73/200 Cost: 11.446070\n",
      "Epoch   74/200 Cost: 11.441924\n",
      "Epoch   75/200 Cost: 11.437774\n",
      "Epoch   76/200 Cost: 11.433623\n",
      "Epoch   77/200 Cost: 11.429502\n",
      "Epoch   78/200 Cost: 11.425340\n",
      "Epoch   79/200 Cost: 11.421206\n",
      "Epoch   80/200 Cost: 11.417083\n",
      "Epoch   81/200 Cost: 11.412964\n",
      "Epoch   82/200 Cost: 11.408849\n",
      "Epoch   83/200 Cost: 11.404721\n",
      "Epoch   84/200 Cost: 11.400604\n",
      "Epoch   85/200 Cost: 11.396497\n",
      "Epoch   86/200 Cost: 11.392382\n",
      "Epoch   87/200 Cost: 11.388296\n",
      "Epoch   88/200 Cost: 11.384190\n",
      "Epoch   89/200 Cost: 11.380085\n",
      "Epoch   90/200 Cost: 11.375989\n",
      "Epoch   91/200 Cost: 11.371905\n",
      "Epoch   92/200 Cost: 11.367795\n",
      "Epoch   93/200 Cost: 11.363726\n",
      "Epoch   94/200 Cost: 11.359636\n",
      "Epoch   95/200 Cost: 11.355569\n",
      "Epoch   96/200 Cost: 11.351479\n",
      "Epoch   97/200 Cost: 11.347412\n",
      "Epoch   98/200 Cost: 11.343345\n",
      "Epoch   99/200 Cost: 11.339282\n",
      "Epoch  100/200 Cost: 11.335227\n",
      "Epoch  101/200 Cost: 11.331167\n",
      "Epoch  102/200 Cost: 11.327109\n",
      "Epoch  103/200 Cost: 11.323037\n",
      "Epoch  104/200 Cost: 11.319025\n",
      "Epoch  105/200 Cost: 11.314951\n",
      "Epoch  106/200 Cost: 11.310912\n",
      "Epoch  107/200 Cost: 11.306882\n",
      "Epoch  108/200 Cost: 11.302859\n",
      "Epoch  109/200 Cost: 11.298806\n",
      "Epoch  110/200 Cost: 11.294775\n",
      "Epoch  111/200 Cost: 11.290751\n",
      "Epoch  112/200 Cost: 11.286746\n",
      "Epoch  113/200 Cost: 11.282729\n",
      "Epoch  114/200 Cost: 11.278691\n",
      "Epoch  115/200 Cost: 11.274700\n",
      "Epoch  116/200 Cost: 11.270681\n",
      "Epoch  117/200 Cost: 11.266680\n",
      "Epoch  118/200 Cost: 11.262673\n",
      "Epoch  119/200 Cost: 11.258672\n",
      "Epoch  120/200 Cost: 11.254681\n",
      "Epoch  121/200 Cost: 11.250685\n",
      "Epoch  122/200 Cost: 11.246685\n",
      "Epoch  123/200 Cost: 11.242706\n",
      "Epoch  124/200 Cost: 11.238738\n",
      "Epoch  125/200 Cost: 11.234751\n",
      "Epoch  126/200 Cost: 11.230782\n",
      "Epoch  127/200 Cost: 11.226801\n",
      "Epoch  128/200 Cost: 11.222835\n",
      "Epoch  129/200 Cost: 11.218867\n",
      "Epoch  130/200 Cost: 11.214910\n",
      "Epoch  131/200 Cost: 11.210933\n",
      "Epoch  132/200 Cost: 11.206985\n",
      "Epoch  133/200 Cost: 11.203017\n",
      "Epoch  134/200 Cost: 11.199080\n",
      "Epoch  135/200 Cost: 11.195129\n",
      "Epoch  136/200 Cost: 11.191187\n",
      "Epoch  137/200 Cost: 11.187239\n",
      "Epoch  138/200 Cost: 11.183313\n",
      "Epoch  139/200 Cost: 11.179373\n",
      "Epoch  140/200 Cost: 11.175441\n",
      "Epoch  141/200 Cost: 11.171509\n",
      "Epoch  142/200 Cost: 11.167597\n",
      "Epoch  143/200 Cost: 11.163661\n",
      "Epoch  144/200 Cost: 11.159754\n",
      "Epoch  145/200 Cost: 11.155831\n",
      "Epoch  146/200 Cost: 11.151912\n",
      "Epoch  147/200 Cost: 11.148015\n",
      "Epoch  148/200 Cost: 11.144098\n",
      "Epoch  149/200 Cost: 11.140203\n",
      "Epoch  150/200 Cost: 11.136309\n",
      "Epoch  151/200 Cost: 11.132411\n",
      "Epoch  152/200 Cost: 11.128523\n",
      "Epoch  153/200 Cost: 11.124606\n",
      "Epoch  154/200 Cost: 11.120722\n",
      "Epoch  155/200 Cost: 11.116853\n",
      "Epoch  156/200 Cost: 11.112981\n",
      "Epoch  157/200 Cost: 11.109093\n",
      "Epoch  158/200 Cost: 11.105229\n",
      "Epoch  159/200 Cost: 11.101352\n",
      "Epoch  160/200 Cost: 11.097481\n",
      "Epoch  161/200 Cost: 11.093611\n",
      "Epoch  162/200 Cost: 11.089746\n",
      "Epoch  163/200 Cost: 11.085894\n",
      "Epoch  164/200 Cost: 11.082039\n",
      "Epoch  165/200 Cost: 11.078194\n",
      "Epoch  166/200 Cost: 11.074333\n",
      "Epoch  167/200 Cost: 11.070470\n",
      "Epoch  168/200 Cost: 11.066650\n",
      "Epoch  169/200 Cost: 11.062813\n",
      "Epoch  170/200 Cost: 11.058978\n",
      "Epoch  171/200 Cost: 11.055137\n",
      "Epoch  172/200 Cost: 11.051314\n",
      "Epoch  173/200 Cost: 11.047482\n",
      "Epoch  174/200 Cost: 11.043653\n",
      "Epoch  175/200 Cost: 11.039837\n",
      "Epoch  176/200 Cost: 11.036020\n",
      "Epoch  177/200 Cost: 11.032207\n",
      "Epoch  178/200 Cost: 11.028385\n",
      "Epoch  179/200 Cost: 11.024588\n",
      "Epoch  180/200 Cost: 11.020779\n",
      "Epoch  181/200 Cost: 11.016977\n",
      "Epoch  182/200 Cost: 11.013184\n",
      "Epoch  183/200 Cost: 11.009380\n",
      "Epoch  184/200 Cost: 11.005593\n",
      "Epoch  185/200 Cost: 11.001820\n",
      "Epoch  186/200 Cost: 10.998015\n",
      "Epoch  187/200 Cost: 10.994241\n",
      "Epoch  188/200 Cost: 10.990464\n",
      "Epoch  189/200 Cost: 10.986681\n",
      "Epoch  190/200 Cost: 10.982896\n",
      "Epoch  191/200 Cost: 10.979127\n",
      "Epoch  192/200 Cost: 10.975351\n",
      "Epoch  193/200 Cost: 10.971592\n",
      "Epoch  194/200 Cost: 10.967827\n",
      "Epoch  195/200 Cost: 10.964082\n",
      "Epoch  196/200 Cost: 10.960330\n",
      "Epoch  197/200 Cost: 10.956553\n",
      "Epoch  198/200 Cost: 10.952808\n",
      "Epoch  199/200 Cost: 10.949067\n",
      "Epoch  200/200 Cost: 10.945332\n"
     ]
    }
   ],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor(x_data)\n",
    "y_train = torch.FloatTensor(y_data)\n",
    "# 모델 초기화\n",
    "W = torch.zeros((3, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr=1e-5)\n",
    "\n",
    "nb_epochs = 200\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    # H(x) 계산\n",
    "    hypothesis = x_train.matmul(W) + b # or .mm or @\n",
    "\n",
    "    # cost 계산\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100번마다 로그 출력\n",
    "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "        epoch, nb_epochs, cost.item()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level Implementation with `nn.Module`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 Cost: 28388.000000\n",
      "Epoch    1/20 Cost: 10504.286133\n",
      "Epoch    2/20 Cost: 3892.179688\n",
      "Epoch    3/20 Cost: 1447.497314\n",
      "Epoch    4/20 Cost: 543.628357\n",
      "Epoch    5/20 Cost: 209.440048\n",
      "Epoch    6/20 Cost: 85.878799\n",
      "Epoch    7/20 Cost: 40.191814\n",
      "Epoch    8/20 Cost: 23.297268\n",
      "Epoch    9/20 Cost: 17.048059\n",
      "Epoch   10/20 Cost: 14.734761\n",
      "Epoch   11/20 Cost: 13.876624\n",
      "Epoch   12/20 Cost: 13.556563\n",
      "Epoch   13/20 Cost: 13.435411\n",
      "Epoch   14/20 Cost: 13.387821\n",
      "Epoch   15/20 Cost: 13.367404\n",
      "Epoch   16/20 Cost: 13.357059\n",
      "Epoch   17/20 Cost: 13.350419\n",
      "Epoch   18/20 Cost: 13.345175\n",
      "Epoch   19/20 Cost: 13.340427\n",
      "Epoch   20/20 Cost: 13.335882\n"
     ]
    }
   ],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor(x_data)\n",
    "y_train = torch.FloatTensor(y_data)\n",
    "# 모델 초기화\n",
    "model = MultivariateLinearRegressionModel()\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
    "\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs+1):\n",
    "    \n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "    \n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "    \n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 20번마다 로그 출력\n",
    "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "        epoch, nb_epochs, cost.item()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    pandas 기초지식이 필요할 것 같다\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "너무 데이터가 크면 `x_data`, `y_data` 를 전부 다 가져오지 말고, 필요한 배치만 가져올 수 밖에 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[PyTorch Data Loading and Processing tutorial](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#iterating-through-the-dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
